{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Threads et GIL\n",
    "\n",
    "Objectif : comprendre comment les threads permettent d'exécuter plusieurs tâches en parallèle du point de vue logique.\n",
    "\n",
    "Points clés :\n",
    "- Un thread partage la mémoire du processus principal.\n",
    "- En Python, le GIL limite le parallélisme pour les tâches CPU-bound.\n",
    "- Les threads restent utiles pour l'I/O (réseau, disque) car l'attente libère le GIL."
   ],
   "id": "27855d79eaf783c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T14:36:33.861829470Z",
     "start_time": "2026-02-09T14:36:32.836145271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Exemple simple de thread : chaque thread exécute la même fonction avec un numéro différent.\n",
    "\n",
    "def travail(numero):\n",
    "    # Affiche le début du traitement pour ce thread.\n",
    "    print(f'Démarrage du travail {numero}')\n",
    "    # Simule une tâche bloquante (I/O) avec un temps d'attente.\n",
    "    time.sleep(1)\n",
    "    # Affiche la fin du traitement pour ce thread.\n",
    "    print(f'Fin du travail {numero}')\n",
    "\n",
    "# Liste qui va stocker les objets Thread.\n",
    "threads = []\n",
    "# Crée plusieurs threads numérotés.\n",
    "for i in range(3):\n",
    "    # Création d'un thread qui va exécuter la fonction travail.\n",
    "    t = threading.Thread(target=travail, args=(i,))\n",
    "    # Conserve une référence au thread pour pouvoir l'attendre.\n",
    "    threads.append(t)\n",
    "    # Démarre l'exécution du thread.\n",
    "    t.start()\n",
    "\n",
    "# Attendre la fin de tous les threads avant de continuer.\n",
    "for t in threads:\n",
    "    # join() bloque jusqu'à la fin du thread.\n",
    "    t.join()\n",
    "\n",
    "# Note: Python a le GIL (Global Interpreter Lock) qui empêche les threads CPU-bound d'être vraiment parallèles."
   ],
   "id": "ba4faacfa2dca15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du travail 0\n",
      "Démarrage du travail 1\n",
      "Démarrage du travail 2\n",
      "Fin du travail 0\n",
      "Fin du travail 1\n",
      "Fin du travail 2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. Utiliser plusieurs coeurs avec multiprocessing\n",
    "\n",
    "Objectif : utiliser plusieurs processus pour contourner le GIL sur des tâches CPU-bound.\n",
    "\n",
    "Points clés :\n",
    "- Chaque processus a sa propre mémoire et son propre GIL.\n",
    "- Le coût de création est plus élevé que pour un thread.\n",
    "- Idéal pour les calculs intensifs."
   ],
   "id": "efe199db84b2be0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T14:36:33.938880933Z",
     "start_time": "2026-02-09T14:36:33.863767162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from multiprocessing import Process, cpu_count\n",
    "\n",
    "# Affiche le nombre de coeurs CPU disponibles.\n",
    "print('\\nNombre de coeurs disponibles:', cpu_count())\n",
    "\n",
    "def travail_cpu(numero):\n",
    "    # Indique le démarrage de la tâche CPU.\n",
    "    print(f'Traitement CPU {numero} démarré')\n",
    "    # Calcul intensif pour simuler une tâche CPU-bound.\n",
    "    total = sum(i*i for i in range(10**6))\n",
    "    # total n'est pas utilisé, mais force le calcul.\n",
    "    print(f'Traitement CPU {numero} terminé')\n",
    "\n",
    "# Liste qui va stocker les objets Process.\n",
    "processes = []\n",
    "# Crée plusieurs processus numérotés.\n",
    "for i in range(2):\n",
    "    # Chaque Process exécute travail_cpu dans un processus séparé.\n",
    "    p = Process(target=travail_cpu, args=(i,))\n",
    "    # Conserve une référence au processus pour pouvoir l'attendre.\n",
    "    processes.append(p)\n",
    "    # Démarre l'exécution du processus.\n",
    "    p.start()\n",
    "\n",
    "# Attendre la fin de tous les processus.\n",
    "for p in processes:\n",
    "    # join() bloque jusqu'à la fin du processus.\n",
    "    p.join()"
   ],
   "id": "66a718f10c53542",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de coeurs disponibles: 20\n",
      "Traitement CPU 0 démarré\n",
      "Traitement CPU 1 démarré\n",
      "Traitement CPU 0 terminéTraitement CPU 1 terminé\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Programmation I/O asynchrone\n",
    "\n",
    "Objectif : utiliser asyncio pour gérer plusieurs opérations I/O sans créer de threads.\n",
    "\n",
    "Points clés :\n",
    "- Une seule boucle d'événements orchestre des coroutines.\n",
    "- Très efficace pour des milliers de connexions réseau.\n",
    "- Ne convient pas aux calculs CPU lourds."
   ],
   "id": "cee27d5e62eb1ff3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T14:36:55.301445650Z",
     "start_time": "2026-02-09T14:36:52.693332354Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install aiohttp",
   "id": "8993a900238120f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\r\n",
      "  Downloading aiohttp-3.13.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp)\r\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp)\r\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp)\r\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\r\n",
      "  Downloading multidict-6.7.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp)\r\n",
      "  Downloading propcache-0.4.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp)\r\n",
      "  Downloading yarl-1.22.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.11)\r\n",
      "Downloading aiohttp-3.13.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\r\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (234 kB)\r\n",
      "Downloading multidict-6.7.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\r\n",
      "Downloading propcache-0.4.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (204 kB)\r\n",
      "Downloading yarl-1.22.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\r\n",
      "Installing collected packages: propcache, multidict, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp\r\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 attrs-25.4.0 frozenlist-1.8.0 multidict-6.7.1 propcache-0.4.1 yarl-1.22.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T14:39:00.453937938Z",
     "start_time": "2026-02-09T14:38:59.431993574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "# Permet d'exécuter asyncio dans un notebook déjà en boucle.\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "\n",
    "async def tache_io(numero):\n",
    "    # Affiche le début de la coroutine.\n",
    "    print(f'Tâche {numero} démarrée')\n",
    "    # await libère la boucle d'événements pendant l'attente.\n",
    "    await asyncio.sleep(1)  # simule une I/O non bloquante\n",
    "    # Affiche la fin de la coroutine.\n",
    "    print(f'Tâche {numero} terminée')\n",
    "\n",
    "async def main():\n",
    "    # Lancer plusieurs coroutines en parallèle logique.\n",
    "    await asyncio.gather(*(tache_io(i) for i in range(3)))\n",
    "\n",
    "# Exécute la boucle d'événements et la coroutine principale.\n",
    "asyncio.run(main())"
   ],
   "id": "64e36de079f217ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tâche 0 démarrée\n",
      "Tâche 1 démarrée\n",
      "Tâche 2 démarrée\n",
      "Tâche 0 terminée\n",
      "Tâche 1 terminée\n",
      "Tâche 2 terminée\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. Performances et éthique\n",
    "\n",
    "Bonnes pratiques pour le scraping et l'automatisation réseau :\n",
    "- Respecter les limites de requêtes (rate limiting).\n",
    "- Ajouter des délais et mettre en cache pour réduire la charge.\n",
    "- Vérifier le fichier robots.txt avant de collecter des données."
   ],
   "id": "75bcb1059c799eb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5. Utilisation d'une forme de cache\n",
    "\n",
    "Objectif : éviter de re-télécharger des données déjà récupérées.\n",
    "\n",
    "Points clés :\n",
    "- Un cache réduit la latence et la charge réseau.\n",
    "- Le stockage disque persiste entre exécutions."
   ],
   "id": "8fa39930a059c07c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T14:39:08.828572525Z",
     "start_time": "2026-02-09T14:39:08.792959252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Nom du fichier de cache.\n",
    "cache_file = 'cache.pkl'\n",
    "\n",
    "# Exemple simple de cache disque : on recharge si le fichier existe.\n",
    "if os.path.exists(cache_file):\n",
    "    # Ouvre le fichier de cache en lecture binaire.\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        # Charge le dictionnaire du cache depuis le disque.\n",
    "        cache = pickle.load(f)\n",
    "else:\n",
    "    # Si le cache n'existe pas, on part d'un dictionnaire vide.\n",
    "    cache = {}\n",
    "\n",
    "# Identifiant de ressource à mettre en cache.\n",
    "url = 'https://example.com/data'\n",
    "if url in cache:\n",
    "    # Si la clé est présente, on réutilise la valeur.\n",
    "    print('\\nDonnées depuis le cache')\n",
    "    data = cache[url]\n",
    "else:\n",
    "    # Sinon, on simule un téléchargement et on ajoute au cache.\n",
    "    print('\\nDonnées simulées et mise en cache')\n",
    "    # Simule une réponse distante.\n",
    "    data = {'value': random.randint(0,100)}\n",
    "    # Sauvegarde dans le dictionnaire de cache.\n",
    "    cache[url] = data\n",
    "    # Écrit le cache mis à jour sur le disque.\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "# Affiche les données finales.\n",
    "print('Données:', data)"
   ],
   "id": "49b1f1e64e2ef968",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données simulées et mise en cache\n",
      "Données: {'value': 70}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "6. Introduire un délai aléatoire\n",
    "\n",
    "Objectif : lisser la charge et éviter les accès trop rapides.\n",
    "\n",
    "Point clé : un délai variable ressemble davantage à un comportement humain."
   ],
   "id": "3ca5a301388403a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "# Délai compris entre 1 et 3 secondes.\n",
    "delay = random.uniform(1, 3)\n",
    "# Affiche la durée de pause choisie.\n",
    "print(f'Pause aléatoire de {delay:.2f} secondes')\n",
    "# Met le programme en pause.\n",
    "time.sleep(delay)\n"
   ],
   "id": "1b2e6955a5f6f186"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "7. Vérifier le fichier robots.txt\n",
    "\n",
    "Objectif : vérifier si un site autorise l'accès à une page.\n",
    "\n",
    "Exemple d'un robot.txt simple :\n",
    "```\n",
    "User-agent: *\n",
    "Disallow: /private/\n",
    "```\n",
    "\n",
    "Ce qui signifie que tous les agents (robots) sont interdits d'accéder à la section /private/ du site.\n",
    "\n",
    "Point clé : robots.txt est une convention, pas un mécanisme de sécurité."
   ],
   "id": "14cb7b24d665f953"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import urllib.robotparser\n",
    "\n",
    "# Crée un parseur pour le fichier robots.txt.\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "# Charger les règles du site ciblé.\n",
    "rp.set_url('https://jsonplaceholder.typicode.com/robots.txt')\n",
    "# Télécharge et parse le robots.txt.\n",
    "rp.read()\n",
    "# Vérifie si un user-agent générique peut accéder à l'URL.\n",
    "can_fetch = rp.can_fetch('*', 'https://jsonplaceholder.typicode.com/posts')\n",
    "# Affiche le résultat de la vérification.\n",
    "print(f'Peut-on scraper la page? {can_fetch}')"
   ],
   "id": "680eb5975cad2ebb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "8. Exercices\n",
    "\n",
    "1. Modifier le cache pour utiliser Redis (requiert installation redis-py et serveur Redis).\n",
    "2. Comparer performance entre threading, multiprocessing et asyncio.\n",
    "3. Implémenter un scraper respectueux qui lit robots.txt, utilise cache et délai aléatoire.\n",
    "\n"
   ],
   "id": "2f2cd424d958a06c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
